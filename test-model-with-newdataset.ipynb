{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNPFqTFZ9nNj",
        "outputId": "c90b4a2a-0e8d-4dd5-faa4-4f68218459f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-20 16:28:44--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4502524724 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.fa.300.bin.gz’\n",
            "\n",
            "cc.fa.300.bin.gz    100%[===================>]   4.19G  32.9MB/s    in 2m 14s  \n",
            "\n",
            "2022-02-20 16:30:59 (32.1 MB/s) - ‘cc.fa.300.bin.gz’ saved [4502524724/4502524724]\n",
            "\n",
            "--2022-02-20 16:32:18--  https://raw.githubusercontent.com/Mehrdadghassabi/Persian-Sentiment-Analyzer/master/better_dataset/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1227632 (1.2M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>]   1.17M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-02-20 16:32:18 (140 MB/s) - ‘test.csv’ saved [1227632/1227632]\n",
            "\n",
            "--2022-02-20 16:32:18--  https://docs.google.com/uc?export=download&id=12CrgrdQF7X91s2fOF7ubjQOFWRVEjlkD\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.45.110, 2607:f8b0:4004:83f::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.45.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-5k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/11f0m8h1ki73vjhf3g8nfgmf93e2cf6e/1645374675000/07219233973886969501/*/12CrgrdQF7X91s2fOF7ubjQOFWRVEjlkD?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-02-20 16:32:20--  https://doc-10-5k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/11f0m8h1ki73vjhf3g8nfgmf93e2cf6e/1645374675000/07219233973886969501/*/12CrgrdQF7X91s2fOF7ubjQOFWRVEjlkD?e=download\n",
            "Resolving doc-10-5k-docs.googleusercontent.com (doc-10-5k-docs.googleusercontent.com)... 142.251.33.193, 2607:f8b0:4004:837::2001\n",
            "Connecting to doc-10-5k-docs.googleusercontent.com (doc-10-5k-docs.googleusercontent.com)|142.251.33.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39919848 (38M) [application/octet-stream]\n",
            "Saving to: ‘best_model.h5’\n",
            "\n",
            "best_model.h5       100%[===================>]  38.07M  66.3MB/s    in 0.6s    \n",
            "\n",
            "2022-02-20 16:32:20 (66.3 MB/s) - ‘best_model.h5’ saved [39919848/39919848]\n",
            "\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.1-py2.py3-none-any.whl (211 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3131796 sha256=c6fd64d14e9e438ed86acb44ce856479702d72e1b099a0316cf18884ba846e99\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.1\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 25.7 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 60.1 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394486 sha256=f8bb0e7c7906352c333ffb3fd39fdf5e33b9eb7540dc3fea0d6429124b017494\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=155076 sha256=787e860176946dfebe79ac2955a47604b8cd104f1432e34471d2ff4d6dccdf5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "!gunzip /content/cc.fa.300.bin.gz\n",
        "!wget https://raw.githubusercontent.com/Mehrdadghassabi/Persian-Sentiment-Analyzer/master/better_dataset/test.csv\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=12CrgrdQF7X91s2fOF7ubjQOFWRVEjlkD' -O 'best_model.h5'\n",
        "!pip install fasttext\n",
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.models import load_model\n",
        "import fasttext \n",
        "import pandas\n",
        "import hazm\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "\n",
        "def clean_text(text):\n",
        "  normalizer = hazm.Normalizer()\n",
        "  text = normalizer.normalize(text)\n",
        "  return text\n",
        "\n",
        "the_size = 300 \n",
        "maxlen = 20\n",
        "model = load_model('best_model.h5')\n",
        "Word_vectors = fasttext.load_model(\"/content/cc.fa.300.bin\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ5Wm31s9rRI",
        "outputId": "196b63ca-0e0a-4995-ea06-c5bf48e807a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pandas.read_csv(\"/content/test.csv\", sep='\t')\n",
        "test_list = list(map(lambda x: [clean_text(x[0]),x[1]],zip(test['comment'],test['label_id'])))\n",
        "test_size=len(test_list)\n",
        "x_test = np.zeros((test_size, maxlen, the_size), dtype=K.floatx())\n",
        "y_test = np.zeros((test_size, 2), dtype=np.int32)\n",
        "\n",
        "for i in range(test_size):\n",
        "  text_words = hazm.word_tokenize(test_list[i][0])\n",
        "  for t in range(0,len(text_words)):\n",
        "    if t >= maxlen:\n",
        "      break\n",
        "    if text_words[t] not in Word_vectors.words:\n",
        "      continue\n",
        "    x_test[i, t, :] = Word_vectors.get_word_vector(text_words[t])\n",
        "  if test_list[i][1] == 1:\n",
        "    y_test[i, :] = [1.0, 0.0]\n",
        "  else:\n",
        "    y_test[i, :] = [0.0, 1.0]\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "y_pred = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "predod =np.empty(len(y_pred))\n",
        "testod =np.empty(len(y_test))\n",
        "\n",
        "for x in range(len(y_pred)) :\n",
        "    if y_pred[x][0] == 1 :\n",
        "      predod[x] = 0\n",
        "    else :\n",
        "      predod[x] = 1\n",
        "\n",
        "for y in range(len(y_test)) :\n",
        "    if y_test[y][0] == 1 :\n",
        "      testod[y] = 0\n",
        "    else :\n",
        "      testod[y] = 1\n",
        "print(confusion_matrix(y_true=predod, y_pred=testod))\n",
        "print(classification_report(y_true=predod, y_pred=testod))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8PRf98I9vaH",
        "outputId": "f6a963c5-de15-4aef-86ad-18d5ce8a3885"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3052  749]\n",
            " [ 448 2751]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.80      0.84      3801\n",
            "         1.0       0.79      0.86      0.82      3199\n",
            "\n",
            "    accuracy                           0.83      7000\n",
            "   macro avg       0.83      0.83      0.83      7000\n",
            "weighted avg       0.83      0.83      0.83      7000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}